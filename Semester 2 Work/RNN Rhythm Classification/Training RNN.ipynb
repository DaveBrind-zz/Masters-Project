{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Code Outline -------- #\n",
    "# Create a model that implements an RNN using output predictions from a CNN in order to identify rhythm changes.\n",
    "# This program was used to actually train the model on the entire set. We used RR + beat label predictions as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, multilabel_confusion_matrix, hamming_loss, jaccard_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
    "from skmultilearn.model_selection import IterativeStratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adb de-noised/100_de-noised.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)\n",
    "end = len(y)\n",
    "#print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will have time series data of labels for each patient. These series will be different lengths so we need to\n",
    "# Pad them all to add 0's to the end of each sequence to get longer length inputs. So first we save how many labels are\n",
    "# In each patient as well as how many beats are in the signal.\n",
    "\n",
    "# Load in the beat labels for each patient as well as the rhythm labels for each\n",
    "\n",
    "patient_id = range(0,48)\n",
    "\n",
    "beat_labels = []\n",
    "\n",
    "beat_locations = []\n",
    "\n",
    "rhythm_labels = []\n",
    "\n",
    "rhythm_locations = []\n",
    "\n",
    "full_test = [14,24]\n",
    "half_test = [4,28,40,41,44,45]\n",
    "\n",
    "test_beat_labels = []\n",
    "test_beat_locations = []\n",
    "test_rhythm_labels = []\n",
    "test_rhythm_locations = []\n",
    "\n",
    "half_beat_labels = []\n",
    "half_beat_locations = []\n",
    "half_rhythm_labels = []\n",
    "half_rhythm_locations = []\n",
    "\n",
    "for i in patient_id:\n",
    "    # Beat labels for patient i\n",
    "    with open('adb final labels/adb beat labels/{}_beat_labels.pkl'.format(i), 'rb') as f:\n",
    "        temp_beat = pickle.load(f)\n",
    "    # beat label locations for patient i\n",
    "    with open('adb final labels/adb peaks/{}_peaks.pkl'.format(i), 'rb') as f:\n",
    "        temp_beat_locations = pickle.load(f)\n",
    "    # rhythm labels for patient i\n",
    "    with open('adb final labels/adb rhythm labels/{}_rhythm_labels.pkl'.format(i), 'rb') as f:\n",
    "        temp_rhythm = pickle.load(f)\n",
    "    # Rhythm label locations for patient i\n",
    "    with open('adb final labels/adb rhythm locations/{}_rhythm_locations.pkl'.format(i), 'rb') as f:\n",
    "        temp_rhythm_location = pickle.load(f)\n",
    "        \n",
    "    # Split into training and testing splits\n",
    "    if(i in full_test):\n",
    "        test_rhythm_locations.append(temp_rhythm_location)\n",
    "        test_beat_labels.append(temp_beat)\n",
    "        test_rhythm_labels.append(temp_rhythm)\n",
    "        test_beat_locations.append(temp_beat_locations)\n",
    "    elif(i in half_test):\n",
    "        half_rhythm_locations.append(temp_rhythm_location)\n",
    "        half_beat_labels.append(temp_beat)\n",
    "        half_rhythm_labels.append(temp_rhythm)\n",
    "        half_beat_locations.append(temp_beat_locations)\n",
    "    else:\n",
    "        rhythm_locations.append(temp_rhythm_location)\n",
    "        beat_labels.append(temp_beat)\n",
    "        rhythm_labels.append(temp_rhythm)\n",
    "        beat_locations.append(temp_beat_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(rhythm_labels))\n",
    "#print(half_rhythm_labels[-1])\n",
    "#print(len(test_rhythm_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now split the half patient test data into half in order to get representative test set\n",
    "index = []\n",
    "for j in half_beat_locations:\n",
    "    # Find beat location nearest to the halfway point\n",
    "    index.append(min(enumerate(j), key=lambda x: abs(x[1]-(end/2)))[0])\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the closest rhythm location to a certain beat location\n",
    "\n",
    "def find_beat_to_rhythm(beat_location, rhythm_location):\n",
    "    index, value = min(enumerate(rhythm_location), key=lambda x: abs(x[1]-(beat_location)))\n",
    "    return index, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have found the beat corresponding to the halfway point of the ecg, and then the function above finds the last rhythm\n",
    "# Label before this point\n",
    "\n",
    "# For every halfway beat in the list above we now need to find the nearest rhythm to it and use that as our starting rhythm\n",
    "\n",
    "for c,k in enumerate(index):\n",
    "    starting_rhythm_index, starting_rhythm_value = find_beat_to_rhythm(half_beat_locations[c][k], half_rhythm_locations[c])\n",
    "    halfway_list_locations = [end / 2]\n",
    "    halfway_list_labels = [half_rhythm_labels[c][starting_rhythm_index]]\n",
    "    \n",
    "    if(c == 0):\n",
    "        # We want left half of patient ECG in the test set\n",
    "        test_rhythm_labels.append(half_rhythm_labels[c][:starting_rhythm_index])\n",
    "        temp_list = half_rhythm_locations[c][:starting_rhythm_index] + [end / 2]\n",
    "        test_rhythm_locations.append(temp_list)\n",
    "        test_beat_labels.append(half_beat_labels[c][:k])\n",
    "        test_beat_locations.append(half_beat_locations[c][:k])\n",
    "        # Save the right half into the training set\n",
    "        temp_labels = halfway_list_labels + half_rhythm_labels[c][(starting_rhythm_index):]\n",
    "        rhythm_labels.append(temp_labels)\n",
    "        temp_locations = halfway_list_locations + half_rhythm_locations[c][(starting_rhythm_index):]\n",
    "        rhythm_locations.append(temp_locations)\n",
    "        beat_labels.append(half_beat_labels[c][k:])\n",
    "        beat_locations.append(half_beat_locations[c][k:])\n",
    "    else:\n",
    "        # We want right half of patient ECG in the test set\n",
    "        test_rhythm_labels.append(half_rhythm_labels[c][(starting_rhythm_index - 1):])\n",
    "        temp_list =  [end / 2] + half_rhythm_locations[c][starting_rhythm_index:]\n",
    "        test_rhythm_locations.append(temp_list)\n",
    "        test_beat_labels.append(half_beat_labels[c][k:])\n",
    "        test_beat_locations.append(half_beat_locations[c][k:])\n",
    "        # Save the left half into the training set\n",
    "        if(len(half_rhythm_labels[c]) == 1): # If we only have one rhythm present in the sample\n",
    "            temp_labels = [half_rhythm_labels[c][0]]\n",
    "            temp_locations = [half_rhythm_locations[c][0]]\n",
    "        else:\n",
    "            temp_labels = half_rhythm_labels[c][:starting_rhythm_index]\n",
    "            temp_locations = half_rhythm_locations[c][:starting_rhythm_index]\n",
    "        rhythm_labels.append(temp_labels)\n",
    "        rhythm_locations.append(temp_locations)\n",
    "        beat_labels.append(half_beat_labels[c][:k])\n",
    "        beat_locations.append(half_beat_locations[c][:k])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(rhythm_locations))\n",
    "#print(len(test_rhythm_locations))\n",
    "#print(test_rhythm_labels[2])\n",
    "#print(test_rhythm_locations[2])\n",
    "#print(rhythm_locations[-1])\n",
    "#print(rhythm_labels[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_beat_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to remove the last beat from the arrays as this is usually erroneous due to disconnection of ECG\n",
    "# Can only do this for the latter half of each training set but for the first half of patients [28,40,41,44,45] we have only\n",
    "# The left hand side of the ECG so the last labels etc are fine. We appended these on last so the last 5 patients do not need\n",
    "# Changing\n",
    "\n",
    "for i in beat_locations:\n",
    "    del i[-1]\n",
    "for j in beat_labels:   \n",
    "    del j[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "#beat_locations[6][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the starting and ending points of all the rhythms, we need to create windows of pre-determined\n",
    "# Sample size and then these will be given a target label in the form of a vector. This vector will tell us which \n",
    "# Rhythms are present within the sample.\n",
    "\n",
    "# Choose a sample size - The number of beat labels you are going to send in\n",
    "sample_size = 10\n",
    "\n",
    "# Now we need to create sublists for each patient with 10 beat labels in\n",
    "full_list = []\n",
    "for j in beat_labels:\n",
    "    samples = [j[i * sample_size:(i + 1) * sample_size] for i in range((len(j) + sample_size - 1) // sample_size )]\n",
    "    full_list.append(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "#print(len(full_list[0]))\n",
    "#print(full_list[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to replace each type with their corresponding integer number\n",
    "integer_samples = [[[0 if b == 'N'\n",
    "          else 1 if b == 'L'\n",
    "          else 2 if b == 'R'\n",
    "          else 3 if b == 'A'\n",
    "          else 4 if b == 'a'\n",
    "          else 5 if b == 'J'\n",
    "          else 6 if b == 'S'\n",
    "          else 7 if b == 'V'\n",
    "          else 8 if b == 'F'\n",
    "          else 9 if b == '!'\n",
    "          else 10 if b == 'e'\n",
    "          else 11 if b == 'j'\n",
    "          else 12 if b == 'E'\n",
    "          else 13 if b == '/'\n",
    "          else 14 if b == 'f'\n",
    "          else 15 if b == 'x'\n",
    "          else 16 if b == 'Q'\n",
    "          else 17 for b in j] for j in k] for k in full_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "#print(integer_samples[0][90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "#print(full_list[2][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now some of the samples will be missing beats so for these we need to pad them with arbitrary values \n",
    "# To make them 10 in length\n",
    "\n",
    "# Loop over the samples and pad the last elements\n",
    "for i in integer_samples:\n",
    "    for c,j in enumerate(i):\n",
    "        if (c == (len(i) - 1)):\n",
    "            # Pad last sample\n",
    "            element_to_add = sample_size - len(j)\n",
    "            for k in range(element_to_add):\n",
    "                new = [99]\n",
    "                j = j + new\n",
    "            i[c] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "#print(integer_samples[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have loads of samples in integer format with the encoding from above. We now need to go through and\n",
    "# Create new vector label arrays of dimension (15,) in form [1,0,0,0.....] if it is a Atrial bigeminy\n",
    "# [0,1,0,0,0,0...] if it is a Atrial fibrillation etc. If the sample contains a mixture of rhythms then we opt for\n",
    "# A label such as [1,1,0,0,0....] for AF and atrial bigeminy\n",
    "\n",
    "# Now we need to create sublists for each patient with 10 beat label locations in\n",
    "location_list = []\n",
    "for j in beat_locations:\n",
    "    samples = [j[i * sample_size:(i + 1) * sample_size] for i in range((len(j) + sample_size - 1) // sample_size )]\n",
    "    location_list.append(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(rhythm_locations[-2])\n",
    "#print(location_list[-1][-1])\n",
    "#print(rhythm_labels[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to loop over every sample and check where the beat labels fit into with regards to the rhythm ranges\n",
    "# For ease we will assume the first few samples up the rhythm label are also the same rhythm.\n",
    "# Rhythm labels:\n",
    "# AB - atrial bigeminy (0), AFIB - atrial fibrillation(1), AFL - atrial flutter(2), B - ventricular bigeminy(3)\n",
    "# BII - 2 heart block(4), IVR - idioventricular rhythm(5), N - normal sinus rhythm(6), NOD - nodal rhythm(7)\n",
    "# P - paced rhythm(8), PREX - pre-excitation(9), SBR - sinus brachycardia(10), SVTA - supraventricular tachyarrhymia(11)\n",
    "# T - ventricular trigeminy(12), VFL - ventricular flutter(13), VT - ventricular tachycardia(14)\n",
    "\n",
    "sample_labels = []\n",
    "\n",
    "# First pick a patient\n",
    "for i,patient in enumerate(rhythm_locations):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    patient_beat_labels = []\n",
    "    \n",
    "    # Now loop over all the beat labels in that patients data\n",
    "    for beat_location in beat_locations[i]:\n",
    "        \n",
    "        # Loop over all the rhythms and find which one it is after and use that rhythm label\n",
    "        \n",
    "        rhythm_after = []\n",
    "        \n",
    "        for c,rhythm_location in reversed(list(enumerate(patient))):\n",
    "            if (len(rhythm_after) > 0):\n",
    "                break\n",
    "            else:\n",
    "                if(beat_location > rhythm_location):\n",
    "                    rhythm_after.append(rhythm_labels[i][c])\n",
    "                    #print(rhythm_labels[i][c])\n",
    "                \n",
    "        patient_beat_labels.append(rhythm_after)\n",
    "        #print(patient_beat_labels[-1])\n",
    "       # print(beat_location)\n",
    "        #print(i)\n",
    "        \n",
    "    sample_labels.append(patient_beat_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sample_labels[-1])\n",
    "#print(len(beat_locations[8]))\n",
    "#print(beat_locations[8][90:110])\n",
    "#print(rhythm_locations[8])\n",
    "#print(rhythm_labels[8][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the rhythms set up we need to segment into blocks of sample_size again\n",
    "\n",
    "full_list_labels = []\n",
    "for j in sample_labels:\n",
    "    samples_labels = [j[i * sample_size:(i + 1) * sample_size] for i in range((len(j) + sample_size - 1) // sample_size )]\n",
    "    full_list_labels.append(samples_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "# Per patient\n",
    "for c,i in enumerate(full_list_labels):\n",
    "    print(c)\n",
    "    patient = []\n",
    "    # Each sample\n",
    "    for j in i:\n",
    "        new = []\n",
    "        # Get rid of annoying list notation\n",
    "        for k in j:\n",
    "            try:\n",
    "                new.append(k[0])\n",
    "            except IndexError:\n",
    "                print(k)\n",
    "            #new.append(k[0])\n",
    "        patient.append(new)\n",
    "    x.append(patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x[-2][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(integer_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in an array of sample_labels as well as a boolean ~(tells us if there is a mixture or not)~\n",
    "# We then create a corresponding vector for that sample\n",
    "def create_complete_label(sample_labels):\n",
    "\n",
    "    # Doing this finds the UNIQUE elements of the sample_labels\n",
    "    unique_elements = list(set(sample_labels))\n",
    "    \n",
    "    #print(unique_elements)\n",
    "    #for i in unique_elements:\n",
    "        #print(i)\n",
    "        \n",
    "    # Create vector - some reason they have a bracket in front of all of them when you extract them\n",
    "    label = [0 if b == 'AB'\n",
    "        else 1 if b == 'AFIB'\n",
    "        else 2 if b == 'AFL'\n",
    "        else 3 if b == 'B'\n",
    "        else 4 if b == 'BII'\n",
    "        else 5 if b == 'IVR'\n",
    "        else 6 if b == 'N'\n",
    "        else 7 if b == 'NOD'\n",
    "        else 8 if b == 'P'\n",
    "        else 9 if b == 'PREX'\n",
    "        else 10 if b == 'SBR'\n",
    "        else 11 if b == 'SVTA'\n",
    "        else 12 if b == 'T'\n",
    "        else 13 if b == 'VFL'\n",
    "        # This one is VT label\n",
    "        else 14 for b in unique_elements]\n",
    "        \n",
    "    # Return the vector\n",
    "    return(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_labels = []\n",
    "for i in x:\n",
    "    patient_l = []\n",
    "    for j in i:\n",
    "        patient_l.append(create_complete_label(j))\n",
    "        \n",
    "    complete_labels.append(patient_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(complete_labels[-1])\n",
    "#print(rhythm_labels[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to transfer these into vectors like [1,0,0,0,0,0,0,0,0,0...] if label 1 is present or\n",
    "# [1,1,0,0,0,0,0,0,0....] if a mixture of label 1 or 2 are present etc.\n",
    "\n",
    "y = []\n",
    "\n",
    "# Loop over every sample and create a vector for it and append it to a list\n",
    "for c,patient in enumerate(complete_labels):\n",
    "    \n",
    "    for sample in patient:\n",
    "        \n",
    "        # Create a label vector\n",
    "        temp = np.zeros((15,))\n",
    "        \n",
    "        # Find which numbers are present, then these indices need to be set to 1\n",
    "        for item in sample:\n",
    "            temp[item] = 1\n",
    "            \n",
    "        y.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have complete set of target labels and input arrays\n",
    "# Check\n",
    "#print(integer_samples[0])\n",
    "# Need to convert integer_samples to a 1 dimensional array of 25 sample windows\n",
    "#print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in integer_samples:\n",
    "    for j in i:\n",
    "        x.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(len(y), sample_size,1)\n",
    "#print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- SECTION FOR RR INTERVAL ADDITION -------- #\n",
    "# See what effect adding RR interval lengths will do if we use it as a second feature.\n",
    "# Each peak will take a value for its RR length to then next peak, except the last one which will just\n",
    "# Be set to 0\n",
    "\n",
    "# First split each patients beats into chunks of sample size\n",
    "patient_sizes = []\n",
    "new_locations = []\n",
    "for k in range(len(beat_locations)):\n",
    "    \n",
    "    patient_sizes.append(len(beat_locations[k]) / sample_size)\n",
    "    \n",
    "    new_locations.append([beat_locations[k][i:i + sample_size] for i in range(0, len(beat_locations[k]), sample_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now find the distance between all the R peaks within that window and set the very final one to 0 so it is same length\n",
    "def distance(point1, point2):\n",
    "    return(abs(point1 - point2))\n",
    "\n",
    "RR_distances = []\n",
    "for patient in new_locations:\n",
    "    patient_RR = []\n",
    "    for c,sample in enumerate(patient):\n",
    "        temp = []\n",
    "        \n",
    "        if (c != len(patient) - 1):\n",
    "            for i in range(0, sample_size, 1):\n",
    "                if(i == sample_size - 1):\n",
    "                    temp += [0]\n",
    "                else:    \n",
    "                    temp += [distance(sample[i],sample[i+1])]\n",
    "        \n",
    "        # Last set for patient will not be a complete set of sample size so work out what is in there to do then pad with 0's\n",
    "        else:\n",
    "        \n",
    "            number_peaks = len(sample)\n",
    "            \n",
    "            number_to_pad = sample_size - number_peaks\n",
    "            \n",
    "            for i in range(0, number_peaks, 1):\n",
    "                if(i == number_peaks - 1):\n",
    "                    temp += [0]\n",
    "                else:\n",
    "                    temp += [distance(sample[i],sample[i+1])]\n",
    "                    \n",
    "            for j in range(number_to_pad):\n",
    "                temp += [0]\n",
    "        \n",
    "        patient_RR.append(temp)\n",
    "    RR_distances += patient_RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_distances = np.array(RR_distances).reshape((x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(RR_distances.shape)\n",
    "#print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(RR_distances[0])\n",
    "#print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have two arrays that we need to join together to get 2 feature arrays\n",
    "total_x = np.concatenate((x,RR_distances), axis = 2)\n",
    "#print(total_x.shape)\n",
    "#print(total_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y[170])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now define a function that finds proportions of the different labels\n",
    "\n",
    "def proportions(labels):\n",
    "    \n",
    "    # Data is in vector form so [1,0,0,0,0....] etc with this indicating it is the first rhythm\n",
    "    # We need to loop over the vector to find where the 1's are then we can get the proportion that is a certain type\n",
    "    \n",
    "    n_mixed, n_pure, n_AB, n_AFIB, n_AFL, n_B, n_BII, n_IVR, n_N, n_NOD, n_P, n_PREX, n_SBR, n_SVTA, n_T, n_VFL, n_VT = 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "    \n",
    "    options = {0 : n_AB,\n",
    "           1 : n_AFIB,\n",
    "           2 : n_AFL,\n",
    "           3 : n_B,\n",
    "           4 : n_BII,\n",
    "           5 : n_IVR,\n",
    "           6 : n_N,\n",
    "           7 : n_NOD,\n",
    "           8 : n_P,\n",
    "           9 : n_PREX,\n",
    "          10 : n_SBR,\n",
    "          11 : n_SVTA,\n",
    "          12 : n_T,\n",
    "          13 : n_VFL,\n",
    "          14 : n_VT,\n",
    "          15 : n_mixed,\n",
    "          16 : n_pure\n",
    "}\n",
    "\n",
    "    for i in labels:\n",
    "        #print(i)\n",
    "        mix = False\n",
    "        count = 0\n",
    "        for index,number in enumerate(i):\n",
    "            #print(count)\n",
    "            #print(number)\n",
    "            \n",
    "            #if ((number == 1) and (index == 0)):\n",
    "                #print(i)\n",
    "            \n",
    "            if(number == 1):\n",
    "                count += 1\n",
    "            \n",
    "                # Change variable in dictionary to one up\n",
    "                options[index] += 1\n",
    "                \n",
    "            elif(number == 0):\n",
    "                count = count\n",
    "        \n",
    "        if(count >= 2):\n",
    "                mix = True\n",
    "                options[15] += 1\n",
    "        elif(count == 1):\n",
    "                mix = False\n",
    "                options[16] += 1\n",
    "                \n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = proportions(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data_split)\n",
    "\n",
    "# This checks we have correct number of samples\n",
    "#print(data_split[15] + data_split[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training data and training labels\n",
    "#with open('RNN Training Data.pkl', 'wb') as f:\n",
    " #   pickle.dump(x, f)\n",
    "#with open('RNN Training Targets.pkl', 'wb') as f:\n",
    " #   pickle.dump(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "batch_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save the indices for GPU use on server\n",
    "#with open('RNN Training Indices.pkl', 'wb') as f:\n",
    " #   pickle.dump(train_indices, f)\n",
    "#with open('RNN Validation Indices.pkl', 'wb') as f:\n",
    " #   pickle.dump(val_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(units = 256,\n",
    "                            stateful = False,\n",
    "                            recurrent_dropout = 0.2,\n",
    "                            activation = 'sigmoid'),\n",
    "                            input_shape = (sample_size,2)))\n",
    "    \n",
    "    \n",
    "model.add(Dense(15, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "# Fit to ALL the data\n",
    "    \n",
    "history = model.fit(total_x, y, verbose = 1, batch_size = batch_size, epochs = 50, shuffle = True)\n",
    "\n",
    "# Save the completed model\n",
    "model.save('RNN Models/RNN Model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
