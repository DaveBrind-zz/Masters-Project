{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This piece of code implements the full testing portion from CNN -> RNN -> output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "import keras\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from keras.applications import MobileNet\n",
    "import sys\n",
    "sys.path.append('P:/')\n",
    "# The generator needed depends on the model. For custom CNN use the first, for transfer learning use the second\n",
    "from Arrhythmia_generator import DataGenerator\n",
    "#from VGG_arrhythmia import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'dim': (128,128),\n",
    "          'batch_size': 1,\n",
    "          'n_classes': 10,\n",
    "          'n_channels': 2,\n",
    "          'shuffle': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bring in the RNN model as well as the CNN model\n",
    "RNN = load_model('RNN Models/RNN Model.h5')\n",
    "\n",
    "# Change model depending on which we are using\n",
    "CNN = load_model('CNN Models/CNN_less_classes_less_norm_oversampling_no_aug.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the transfer learning models I have to send the input images through the conv_base first\n",
    "def mobile(X_train,Y_train):\n",
    "    conv_base = MobileNet(weights='imagenet', include_top=False, input_shape=(128,128,3))\n",
    "    samples_generator = DataGenerator(X_train, Y_train , **params)\n",
    "    test_features = conv_base.predict_generator(samples_generator, verbose=True)\n",
    "    \n",
    "    return test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the patient labels and that\n",
    "   # with open('Teddys Stuff/Test Data/Patient {} IDs.pkl'.format(2), 'rb') as f:\n",
    "    #    ids = pickle.load(f)\n",
    "   # with open('Teddys Stuff/Test Data/Patient {} Labels.pkl'.format(2), 'rb') as f:\n",
    "    #    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loops over every patient and gets the predictions of the beat type\n",
    "predictions = []\n",
    "true_labels = []\n",
    "patient_indexes = []\n",
    "#for i in range(8):\n",
    "# Need to load in the data that is going to be used for testing \n",
    "with open('Test Data/Test IDs Less Classes.pkl', 'rb') as f:\n",
    "    ids = pickle.load(f)\n",
    "with open('Test Data/Test Labels Less Classes OHE.pkl', 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "        \n",
    "        \n",
    "training_generator = DataGenerator(ids, labels , **params)\n",
    "#patient_features = mobile(ids,labels)\n",
    "patient_prediction = CNN.predict_generator(training_generator,verbose = True)\n",
    "    \n",
    "    \n",
    "#predictions.append(patient_prediction)\n",
    "#true_labels.append(labels)\n",
    "#print(len(labels))\n",
    "    #if (i==0):\n",
    "   #     patient_indexes.append(len(labels))\n",
    "    #else:\n",
    "   #     patient_indexes.append(len(labels) + patient_indexes[i - 1])\n",
    "   # print(patient_indexes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(patient_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy so we do not mess up the predictions and have to run it again\n",
    "copy = patient_prediction.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(copy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put ones/zeros at the max element etc\n",
    "copy = (copy == copy.max(axis=1)[:,None]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(copy[0])\n",
    "#print(copy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(copy[3])\n",
    "\n",
    "# Observe all the metrics\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
    "print(accuracy_score(labels,copy))\n",
    "print(precision_score(labels,copy, average = None))\n",
    "print(recall_score(labels,copy, average = None))\n",
    "print(f1_score(labels,copy, average = None))\n",
    "print(precision_score(labels,copy, average = 'micro'))\n",
    "print(recall_score(labels,copy, average = 'micro'))\n",
    "print(f1_score(labels,copy, average = 'micro'))\n",
    "print(multilabel_confusion_matrix(labels,copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to convert these into labels for the RNN so we need to put these x's into labels first\n",
    "# Wherever the 1 is elementwise, we need to save this as its label\n",
    "RNN_x = []\n",
    "\n",
    "for i in copy:\n",
    "    for c,element in enumerate(i):\n",
    "        if(element == 1):\n",
    "            RNN_x.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(RNN_x[:10])\n",
    "RNN_x = np.array(RNN_x)\n",
    "#print(RNN_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now split this array into 10 window chunks\n",
    "rnn_x = [RNN_x[i:i + 10] for i in range(0, len(RNN_x), 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_x = np.array(rnn_x)\n",
    "#print(rnn_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 772 onwards are ! beats only and these all belong to VFL rhythm which we cannot detect therefore remove these\n",
    "rnn_x = list(rnn_x)\n",
    "del rnn_x[772:]\n",
    "rnn_x = np.array(rnn_x)\n",
    "#print(rnn_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(rnn_x[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in the correct labels as well as the test beat locations in order to find RR intervals\n",
    "\n",
    "with open('RNN Models/RNN_Test_y.pkl', 'rb') as f:\n",
    "    rnn_true_y = pickle.load(f)\n",
    "with open('RNN Models/RNN_Test_Beat_Locations.pkl', 'rb') as f:\n",
    "    beat_locations = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(beat_locations[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now find the RR intervals and stack them with the beat label array\n",
    "def distance(point1, point2):\n",
    "    return(abs(point1 - point2))\n",
    "\n",
    "RR_intervals = []\n",
    "for c,sample in enumerate(beat_locations):\n",
    "    temp = []\n",
    "        \n",
    "    for i in range(0, 10, 1):\n",
    "        if(i == 9):\n",
    "            temp += [0]\n",
    "        else:    \n",
    "            temp += [distance(sample[i],sample[i+1])]\n",
    "                \n",
    "    RR_intervals.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_intervals = np.array(RR_intervals)\n",
    "RR_intervals = RR_intervals.reshape((RR_intervals.shape[0], RR_intervals.shape[1], 1))\n",
    "rnn_x = rnn_x.reshape((RR_intervals.shape))\n",
    "#print(RR_intervals.shape)\n",
    "#print(RR_intervals[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_output_x = np.concatenate((rnn_x, RR_intervals), axis = 2)\n",
    "#print(cnn_output_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use these to detect the rhythms\n",
    "rhythm_preds = RNN.predict(cnn_output_x, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(rhythm_preds[0])\n",
    "# Again round the probabilities appropriately\n",
    "rhythm_preds[rhythm_preds > 0.5] = 1\n",
    "rhythm_preds[rhythm_preds <= 0.5] = 0\n",
    "#print(rhythm_preds[0])\n",
    "#print(rnn_true_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now find confusion etc\n",
    "print(accuracy_score(rnn_true_y,rhythm_preds))\n",
    "print(precision_score(rnn_true_y,rhythm_preds, average = None))\n",
    "print(recall_score(rnn_true_y,rhythm_preds, average = None))\n",
    "print(f1_score(rnn_true_y,rhythm_preds, average = None))\n",
    "print(precision_score(rnn_true_y,rhythm_preds, average = 'micro'))\n",
    "print(recall_score(rnn_true_y,rhythm_preds, average = 'micro'))\n",
    "print(f1_score(rnn_true_y,rhythm_preds, average = 'micro'))\n",
    "print(multilabel_confusion_matrix(rnn_true_y,rhythm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try and see what difference removing the mixed labels makes and just treating the rhythms as multiclass problem instead\n",
    "pure_x = []\n",
    "pure_y = []\n",
    "mixed_x = []\n",
    "mixed_y = []\n",
    "\n",
    "for c,label in enumerate(rnn_true_y):\n",
    "    # If it is pure then use it\n",
    "    if(list(label).count(1) == 1):\n",
    "        pure_x.append(cnn_output_x[c])\n",
    "        pure_y.append(label)\n",
    "        \n",
    "    else:\n",
    "        mixed_x.append(cnn_output_x[c])\n",
    "        mixed_y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_x = np.array(pure_x)\n",
    "pure_y = np.array(pure_y)\n",
    "#print(pure_x.shape)\n",
    "#print(pure_y.shape)\n",
    "\n",
    "mixed_x = np.array(mixed_x)\n",
    "mixed_y = np.array(mixed_y)\n",
    "#print(mixed_x.shape)\n",
    "#print(mixed_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now send through RNN and see results\n",
    "Multiclass_RNN = load_model('RNN Models/Multiclass.h5')\n",
    "\n",
    "mixed_preds = RNN.predict(mixed_x,verbose = True)\n",
    "mixed_preds[mixed_preds > 0.5] = 1\n",
    "mixed_preds[mixed_preds <= 0.5] = 0\n",
    "\n",
    "pure_preds = Multiclass_RNN.predict(pure_x, verbose = True)\n",
    "pure_preds[pure_preds > 0.5] = 1\n",
    "pure_preds[pure_preds <= 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(mixed_y,mixed_preds))\n",
    "print(precision_score(mixed_y,mixed_preds, average = None))\n",
    "print(recall_score(mixed_y,mixed_preds, average = None))\n",
    "print(f1_score(mixed_y,mixed_preds, average = None))\n",
    "print(precision_score(mixed_y,mixed_preds, average = 'micro'))\n",
    "print(recall_score(mixed_y,mixed_preds, average = 'micro'))\n",
    "print(f1_score(mixed_y,mixed_preds, average = 'micro'))\n",
    "print(multilabel_confusion_matrix(mixed_y,mixed_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(pure_y,pure_preds))\n",
    "print(precision_score(pure_y,pure_preds, average = None))\n",
    "print(recall_score(pure_y,pure_preds, average = None))\n",
    "print(f1_score(pure_y,pure_preds, average = None))\n",
    "print(np.mean(precision_score(pure_y,pure_preds, average = None)))\n",
    "print(np.mean(recall_score(pure_y,pure_preds, average = None)))\n",
    "print(np.mean(f1_score(pure_y,pure_preds, average = None)))\n",
    "#print(multilabel_confusion_matrix(pure_y,pure_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print((0.87356322 + 0.96969697 + 0.90501601 +  0.64705882 + 0.96428571 + 1 + 0)/7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
